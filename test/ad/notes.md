腾讯2017社交广告大赛中的解决方案，之后代码会陆续更新到上面。


排名：Amelie 30th. 成绩:0.102001


简介:
1 我们的特征数量一度达到了100多维，这对我们的机器提出了很高的要求。所幸我们通过各种方法得到了一台256G的服务器，刚好满足我们的需求。一次结果大概需要1个多小时的计算。由于特征是我们通过各种手段抽取出来的，这里我们就不贴出特征的抽取代码。
2 我们原始模型只使用了28，29两天的数据。
3

主要工作：


1 针对业务的特征工程
2 使用lightgbm来抽取特征，预测app转化率
3 探索了ffm的使用(基于lightgbm抽取得到的特征)
4 小技巧
  1 贝叶斯平滑
  2 (tricks)探测平台的平均转化率，然后所有转化率以此乘以一个ratio
3 Facebook的sample技巧，sample之后数据变成原来的几分之一，但是效果只有微笑下降。在这里效果不好，但是如果数据集再大一些，应该能有很大作用。


截止比赛完成暂未完成的工作:


1 lightgbm stacking策略
2 多模型投票(各个模型的结果加权平均xgboost,lightgbm,ffm等)


近期任务：
1 补全工程中缺失，不明确的部分。补全说明文档。
2 完善ffm代码。


别人的思路分享：

1st nju_newbie 0.100787
框架：数据预处理，数据去噪，特征提取，模型构建和模型融合
特征抽取：转化率，点击特征，安装特征和时间特征
模型:GBDT(lightGBM),wide&deep网络，pnn网络和nffm网络

2nd Raymone 0.100868
框架：数据清洗，数据划分，特征提取，模型训练和模型融合
数据清洗：
1 由于转化回流时间有长有短，所以最后五天的label可能是不准确的，尤其是第30天。如果将第30天的数据全部删除，将会丢失大量有用的信息。如果全部保留，又引进了相当程度的噪声。而我们发现，转化回流时间是与APP ID有关的。于是我们统计了每个APP ID的平均转化回流时间，并且删除掉了第30天中平均转化回流时间偏长的数据。
模型融合:
1 我们模型融合采用的是Stacking方法。除了LightGBM之外，我们又训练了FFM,LR,GBDT(xgboost),ET模型。最终Stacking帮助我们提高了2.5个万分点左右。

3rd 我很难受 0.101017
模型融合:xgb,lgb,ffm


