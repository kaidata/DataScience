{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from feature_joint import addTime,addAd,addPosition,addAppCategories,addUserInfo\n",
    "from _2_1_gen_user_click_features import add_user_day_click_count,add_user_day_hour_count,add_user_click_stats,add_user_day_click\n",
    "from _2_2_gen_app_install_features import add_user_hist_install,add_user_start_installed_cateA\n",
    "from _2_3_gen_global_sum_counts import add_global_count_sum\n",
    "from _2_4_gen_tricks import add_tricks\n",
    "from _2_5_gen_smooth_cvr import add_hist_cvr_smooth,add_smooth_pos_cvr\n",
    "from _2_6_gen_ID_click_vectors import get_ConcatedTfidfVector_ID_user_clicks\n",
    "\n",
    "from utils import load_pickle,dump_pickle,get_feature_value,feature_spearmanr,feature_target_spearmanr,addCrossFeature,calibration\n",
    "from utils import raw_data_path,feature_data_path,cache_pkl_path,analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(start_day=23,end_day=26,load_test=False):\n",
    "    \"\"\"\n",
    "    读取基本表拼接后的数据\n",
    "    test表load_test = True\n",
    "    \"\"\"\n",
    "    if load_test ==True:\n",
    "        trans_train_path = feature_data_path+'trans_test_'+str(start_day)+'_'+str(end_day)+'.pkl'\n",
    "        raw_train_path = raw_data_path +'test.pkl'\n",
    "    else:\n",
    "        trans_train_path = feature_data_path+'trans_train_'+str(start_day)+'_'+str(end_day)+'.pkl'\n",
    "        raw_train_path = raw_data_path +'train.pkl'\n",
    "\n",
    "    if os.path.exists(trans_train_path):\n",
    "        print('found '+trans_train_path)\n",
    "        train = pickle.load(open(trans_train_path,'rb'))\n",
    "    else:\n",
    "        print('generating '+trans_train_path)\n",
    "        train = load_pickle(raw_train_path)\n",
    "\n",
    "        train = addTime(train)\n",
    "        train = train[(train.clickDay>=start_day)&(train.clickDay<=end_day)]\n",
    "        train = addAd(train)\n",
    "        train = addPosition(train)\n",
    "        train = addAppCategories(train)\n",
    "        train = addUserInfo(train)\n",
    "             \n",
    "        dump_pickle(train,trans_train_path)\n",
    "    return train\n",
    "\n",
    "\n",
    "def merge_ID_vector(split_train_x,split_test_x,ID_name,last_day,concated_list=['age_cut', 'gender', 'education', 'marriageStatus', 'haveBaby',],mode='local'):\n",
    "    a = get_ConcatedTfidfVector_ID_user_clicks(ID_name,last_day,mode,concated_list=concated_list,drop_na=False)\n",
    "    split_train_x = pd.merge(split_train_x,a,'left',ID_name)\n",
    "    split_test_x = pd.merge(split_test_x,a,'left',ID_name)\n",
    "    return split_train_x,split_test_x\n",
    "    \n",
    "def gen_online_data(train_start_day,train_end_day,test_day):\n",
    "    \n",
    "    train_x_path = cache_pkl_path +'online_train_x_'+str(train_start_day)+'_'+str(train_end_day)+'.pkl'\n",
    "    test_x_path = cache_pkl_path + 'online_test_x_'+str(test_day)+'_'+str(test_day)+'.pkl'\n",
    "    \n",
    "    alpha = 0.647975342478\n",
    "    beta = 34.83752176\n",
    "    pos_na = alpha / (alpha + beta)\n",
    "    \n",
    "    if os.path.exists(train_x_path):\n",
    "        print('found '+train_x_path)\n",
    "        train_x  = load_pickle(train_x_path)\n",
    "    else:\n",
    "        print('generating '+train_x_path)\n",
    "        train_x = load_data(train_start_day,train_end_day,False)\n",
    "        train_x['age_cut']=pd.cut(train_x['age'],bins=[-1,0,18,25,35,45,55,65,np.inf],labels=False)\n",
    "        \n",
    "        #-----------trick-------------------------------\n",
    "        train_x = add_tricks(train_x)\n",
    "        #-----------intstall和action表相关----------------------\n",
    "        print('adding install and actions...')\n",
    "        train_x = add_user_start_installed_cateA(train_x)\n",
    "        train_x = add_user_hist_install(train_x,'train')\n",
    "         #-----------用户点击相关---------------------------- \n",
    "        print('adding user clicks...')\n",
    "        train_x = add_user_day_click_count(train_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        train_x = add_user_day_hour_count(train_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        train_x = add_user_day_click(train_x)\n",
    "        train_x = add_user_click_stats(train_x,)\n",
    "         #------------转化率相关------------------------------\n",
    "        print('adding conversions')\n",
    "        train_x = add_smooth_pos_cvr(train_x,test_day)\n",
    "        train_x = train_x.fillna({'positionID_cvr_smooth': pos_na})\n",
    "        for cvr_key in [ 'creativeID', 'adID', 'appID','userID']:\n",
    "            train_x = add_hist_cvr_smooth(train_x,cvr_key)\n",
    "\n",
    "        #--------------其他------------------------------------\n",
    "        train_x = add_global_count_sum(train_x,test_day,stats_features=['positionID', 'creativeID', 'appID', 'adID', 'userID'])\n",
    "        \n",
    "        \n",
    "        dump_pickle(train_x,train_x_path)\n",
    "    \n",
    "    if os.path.exists(test_x_path):\n",
    "        print('found '+test_x_path)\n",
    "        test_x  = load_pickle(test_x_path)\n",
    "    else:\n",
    "        print('generating '+test_x_path)\n",
    "        test_x = load_data(test_day,test_day,True)\n",
    "        test_x['age_cut']=pd.cut(test_x['age'],bins=[-1,0,18,25,35,45,55,65,np.inf],labels=False)\n",
    "        \n",
    "        #-----------trick-------------------------------\n",
    "        test_x = add_tricks(test_x)\n",
    "        #-----------intstall和action表相关----------------------\n",
    "        print('adding install and actions...')\n",
    "        test_x = add_user_start_installed_cateA(test_x)\n",
    "        test_x = add_user_hist_install(test_x,'test')\n",
    "         #-----------用户点击相关---------------------------- \n",
    "        print('adding user clicks...')\n",
    "        test_x = add_user_day_click_count(test_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        test_x = add_user_day_hour_count(test_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        test_x = add_user_day_click(test_x)\n",
    "        test_x = add_user_click_stats(test_x,)\n",
    "         #------------转化率相关------------------------------\n",
    "        print('adding conversions')\n",
    "        test_x = add_smooth_pos_cvr(test_x,test_day)\n",
    "        test_x = test_x.fillna({'positionID_cvr_smooth': pos_na})\n",
    "        for cvr_key in [ 'creativeID', 'adID', 'appID','userID']:\n",
    "            test_x = add_hist_cvr_smooth(test_x,cvr_key)\n",
    "\n",
    "        #--------------其他------------------------------------\n",
    "        test_x = add_global_count_sum(test_x,test_day,stats_features=['positionID', 'creativeID', 'appID', 'adID', 'userID'])\n",
    "       \n",
    "        dump_pickle(test_x,test_x_path)\n",
    "        \n",
    "    train_x,test_x = merge_ID_vector(train_x,test_x,'advertiserID',last_day=test_day,concated_list=['age_cut', 'gender', 'education', 'marriageStatus', 'haveBaby'])\n",
    "    train_x,test_x = merge_ID_vector(train_x,test_x,'appID',last_day=test_day,concated_list=['age_cut', 'gender', 'education', 'marriageStatus', 'haveBaby'])\n",
    "    \n",
    "    return train_x,test_x\n",
    "  \n",
    "\n",
    "def gen_offline_data(train_start_day,train_end_day,test_day,):\n",
    "    \n",
    "    train_x_path = cache_pkl_path +'offline_train_x_'+str(train_start_day)+'_'+str(train_end_day)+'.pkl'\n",
    "    test_x_path = cache_pkl_path + 'offline_test_x_'+str(test_day)+'_'+str(test_day)+'.pkl'\n",
    "    if os.path.exists(train_x_path) and os.path.exists(test_x_path):\n",
    "        print('found offline data')\n",
    "        train_x = load_pickle(train_x_path)\n",
    "        test_x = load_pickle(test_x_path)\n",
    "    else:\n",
    "        alpha = 0.640792339811\n",
    "        beta = 34.2999347427\n",
    "        pos_na = alpha / (alpha + beta)\n",
    "        \n",
    "        print('generating offline data')\n",
    "        train_x = load_data(train_start_day,test_day,False)\n",
    "        train_x['age_cut']=pd.cut(train_x['age'],bins=[-1,0,18,25,35,45,55,65,np.inf],labels=False)\n",
    "            \n",
    "        #-----------trick-------------------------------\n",
    "        train_x = add_tricks(train_x)\n",
    "        #-----------intstall和action表相关----------------------\n",
    "        print('adding install and actions...')\n",
    "        train_x = add_user_start_installed_cateA(train_x)\n",
    "        train_x = add_user_hist_install(train_x,)\n",
    "\n",
    "         #-----------用户点击相关---------------------------- \n",
    "        print('adding user clicks...')\n",
    "        train_x = add_user_day_click_count(train_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        train_x = add_user_day_hour_count(train_x,['camgaignID','adID','sitesetID','appID',])\n",
    "        train_x = add_user_day_click(train_x)\n",
    "        train_x = add_user_click_stats(train_x,)\n",
    "         #------------转化率相关------------------------------\n",
    "        print('adding conversions')\n",
    "        train_x = add_smooth_pos_cvr(train_x,test_day)\n",
    "        train_x = train_x.fillna({'positionID_cvr_smooth': pos_na})\n",
    "        for cvr_key in [ 'creativeID', 'adID', 'appID','userID']:\n",
    "            train_x = add_hist_cvr_smooth(train_x,cvr_key)\n",
    "\n",
    "        #--------------其他------------------------------------\n",
    "        train_x = add_global_count_sum(train_x,test_day,stats_features=['positionID', 'creativeID', 'appID', 'adID', 'userID'])\n",
    "        #------------分割train和test--------------------------\n",
    "        print('splitting train and test ...')\n",
    "        test_x = train_x[train_x.clickDay==test_day]\n",
    "        train_x = train_x[(train_x.clickDay>=train_start_day)&(train_x.clickDay<=train_end_day)]\n",
    "        dump_pickle(train_x,train_x_path,4)\n",
    "        dump_pickle(test_x,test_x_path,4)\n",
    "    train_x,test_x = merge_ID_vector(train_x,test_x,'advertiserID',last_day=test_day,concated_list=['age_cut', 'gender', 'education', 'marriageStatus', 'haveBaby'])\n",
    "    train_x,test_x = merge_ID_vector(train_x,test_x,'appID',last_day=test_day,concated_list=['age_cut', 'gender', 'education', 'marriageStatus', 'haveBaby'])\n",
    "    return train_x,test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../cache_pkl/online_train_x_25_29.pkl\n",
      "found ../cache_pkl/online_test_x_31_31.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 37.63it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 102.94it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gen_online_data(25,29,31)\n",
    "    #gen_online_data(25,25,31)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
