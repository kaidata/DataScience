{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import load_pickle,dump_pickle,raw_data_path,feature_data_path\n",
    "from feature_joint import addTime,addAd,addPosition,addAppCategories,addUserInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成第一天之前各app被记录的安装数量（根据install）和每天之前各app被记录安装数量（根据action）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_app_start_installed():\n",
    "    \"\"\"\n",
    "    记录第一天之前各个appID被记录的安装数量\n",
    "    拼接键['appID']\n",
    "    \"\"\" \n",
    "    feature_path = feature_data_path + 'app_start_installed.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_install = load_pickle(raw_data_path+'user_installedapps.pkl')\n",
    "        app_start_sum = user_install.groupby('appID').size().reset_index().rename(columns={0:'app_start_install_num'},)\n",
    "        del user_install\n",
    "        gc.collect()\n",
    "        dump_pickle(app_start_sum,feature_path)\n",
    "\n",
    "def add_app_start_installed(data):\n",
    "    feature_path = feature_data_path + 'app_start_installed.pkl'\n",
    "    app_start_installed = load_pickle(feature_path)\n",
    "    data = pd.merge(data,app_start_installed,'left','appID')\n",
    "    return data\n",
    "        \n",
    "def gen_app_hist_install():\n",
    "    \"\"\"\n",
    "    记录截至clickDay前一天，各个appID根据action表统计出的安装量\n",
    "    拼接键['appID','clickDay']\n",
    "    \"\"\"\n",
    "    user_action = pd.read_csv(raw_data_path+'user_app_actions.csv')\n",
    "    feature_path = feature_data_path + 'app_hist_install.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        user_action['installDay'] = user_action['installTime']//1000000\n",
    "        app_hist_install = user_action.groupby(['installDay','appID']).size().reset_index()\n",
    "        app_hist_install.rename(columns={0:'app_day_install'},inplace=True)\n",
    "        app_hist_install['app_hist_install'] = 0  \n",
    "        data_set =None\n",
    "        for day in tqdm(app_hist_install.installDay.unique()):\n",
    "            #df = app_hist_install[app_hist_install.installDay==day]\n",
    "            last_day_install = app_hist_install[app_hist_install.installDay<day].groupby('appID').size().reset_index()\n",
    "            last_day_install.rename(columns={0: 'app_hist_install'}, inplace=True)\n",
    "            last_day_install['Day'] = day\n",
    "            if data_set is None:\n",
    "                data_set = last_day_install\n",
    "            else:\n",
    "                data_set =  pd.concat([data_set,last_day_install])\n",
    "        #添加最后一天的相关信息\n",
    "        last_day_install = app_hist_install[app_hist_install.installDay<31].groupby('appID').size().reset_index()\n",
    "        last_day_install.rename(columns={0: 'app_hist_install'}, inplace=True)\n",
    "        last_day_install['Day'] = 31\n",
    "        data_set =  pd.concat([data_set,last_day_install])\n",
    "        data_set.rename(columns={'Day':'clickDay'},inplace=True)\n",
    "        pickle.dump(data_set,open(feature_path,'wb'))\n",
    "def add_app_hist_install(data):\n",
    "    feature_path = feature_data_path + 'app_hist_install.pkl'\n",
    "    app_hist_install = load_pickle(feature_path)\n",
    "    data = pd.merge(data,app_hist_install,'left',['appID','clickDay'])\n",
    "    app_hist_install['app_hist_install'] = app_hist_install['app_hist_install']/(app_hist_install['clickDay']-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成用户初始安装各大类app数量（根据install）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_start_installed_cateA():\n",
    "    \"\"\"\n",
    "    计算用户初始安装的各大类app的的数量\n",
    "    拼接键['userID',]\n",
    "    \"\"\"\n",
    "    user_install = load_pickle(raw_data_path+'user_installedapps.pkl')\n",
    "    app_cate = pd.read_csv(raw_data_path+'app_categories.csv')\n",
    "    app_cate['cate_a'] = app_cate.appCategory.apply(lambda x:x//100 if x>100 else x)\n",
    "    user_install = user_install.merge(app_cate,'left','appID')\n",
    "    for cate_a in tqdm(app_cate.cate_a.unique()):\n",
    "        feature_path = feature_data_path + 'user_start_installed_cate_'+str(cate_a)+'.pkl'\n",
    "        if os.path.exists(feature_path):\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "            user_install_cate = user_install[user_install.cate_a==cate_a][['userID','cate_a']]\n",
    "            user_install_cate.rename(columns={'cate_a':'user_start_install_cate_'+str(cate_a)},inplace=True) \n",
    "            user_install_cate = user_install_cate.groupby('userID',as_index=False).sum()\n",
    "            dump_pickle(user_install_cate,feature_path)\n",
    "            \n",
    "def add_user_start_installed_cateA(data):\n",
    "    for cate in tqdm([0,1,2,3,4,5]):\n",
    "        feature_path = feature_data_path + 'user_start_installed_cate_'+str(cate)+'.pkl'\n",
    "        user_start_installed_cateA = load_pickle(feature_path)\n",
    "        data = pd.merge(data,user_start_installed_cateA,'left','userID')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户每天之前安装的各大类app数量（根据action）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_hist_install_cateA():\n",
    "    \"\"\"\n",
    "    记录截至clickDay前一天，用户安装的各个大类app总量，根据action表统计\n",
    "    拼接键['userID','clickDay]\n",
    "    \"\"\"\n",
    "    feature_path = feature_data_path + 'user_hist_install_cateA'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_action = pd.read_csv(raw_data_path+'user_app_actions.csv')\n",
    "        app_cate =  pd.read_csv(raw_data_path+'app_categories.csv')\n",
    "        app_cate['cate_a'] = app_cate.appCategory.apply(lambda x:x//100 if x>100 else x)\n",
    "        user_action = user_action.merge(app_cate[['appID','cate_a']],'left','appID')\n",
    "        user_action['installDay'] = user_action['installTime']//10000\n",
    "        user_action = pd.get_dummies(user_action[['userID','cate_a','installDay']],prefix='user_hist_install_cateA',columns=['cate_a'])\n",
    "        stats_columns = ['user_hist_install_cateA_'+str(i) for i in range(0,6)]\n",
    "        user_hist_install_cateA = None\n",
    "        for clickday in tqdm(range(17,32)):\n",
    "            last_day_acc_install = user_action[user_action.installDay<clickday][['userID'] + stats_columns]\n",
    "            last_day_acc_install = last_day_acc_install.groupby('userID',as_index=False).sum()\n",
    "            last_day_acc_install['clickDay'] = clickday\n",
    "            if user_hist_install_cateA is None:\n",
    "                user_hist_install_cateA = last_day_acc_install\n",
    "            else:\n",
    "                user_hist_install_cateA = pd.concat([user_hist_install_cateA,last_day_acc_install],axis=0)\n",
    "        dump_pickle(user_hist_install_cateA,feature_path)\n",
    "def add_user_hist_install_cateA(data):\n",
    "    raise NotImplementedError('NotImplementedError')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算appID初始被各个人群安装的数量（根据install）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_CountVector_appID_user_installed(appID_describe_feature_names=['age_cut','gender','education','marriageStatus','haveBaby','hometown_province','residence_province']):\n",
    "    \"\"\"\n",
    "    生成根据install表计算的appID计数描述向量，可以进行其他后处理\n",
    "    拼接键['appID']\n",
    "    \"\"\"\n",
    "    user_install = load_pickle(raw_data_path+'user_installedapps.pkl')\n",
    "    user_info = pd.read_csv(raw_data_path+'user.csv')\n",
    "    user_info['age_cut']=pd.cut(user_info['age'],bins=[-1,0,18,25,35,45,55,65,np.inf],labels=False)\n",
    "    user_info['hometown_province'] = user_info['hometown'].apply(lambda x: x//100)\n",
    "    user_info['residence_province'] = user_info['residence'].apply(lambda x: x//100)\n",
    "    \n",
    "    for feature in tqdm(appID_describe_feature_names):\n",
    "        feature_path = feature_data_path +'CountVector_appID_user_installed_'+feature+'.pkl'\n",
    "        if os.path.exists(feature_path):\n",
    "            print('found '+feature_path)\n",
    "            continue\n",
    "        print('generating '+feature_path)\n",
    "        sub_user_info =pd.get_dummies(user_info[['userID',feature]],columns=[feature],prefix='appID_installed_'+feature)\n",
    "        user_install = pd.merge(user_install,sub_user_info,'left','userID')\n",
    "        dummy_features= sub_user_info.columns.tolist()\n",
    "        dummy_features.remove('userID')\n",
    "        app_describe_feature = None\n",
    "        for dummy_feature in tqdm(dummy_features):\n",
    "            app_feature_installed = user_install[['appID',dummy_feature]].groupby('appID',as_index=False).sum()\n",
    "            if app_describe_feature is None:\n",
    "                app_describe_feature = app_feature_installed\n",
    "            else:\n",
    "                app_describe_feature = pd.concat([app_describe_feature,app_feature_installed[[dummy_feature]]],axis=1)\n",
    "            user_install.drop(dummy_feature,inplace=True,axis=1)\n",
    "        dump_pickle(app_describe_feature,feature_path)\n",
    "        #print('generated '+feature_path)\n",
    "def get_ConcatedAppIDTfidfVector_userinstalled(concated_list = ['age_cut','gender','education','marriageStatus','haveBaby',],mode='local',norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False):\n",
    "    \"\"\"\n",
    "    拼接键['appID']\n",
    "    \"\"\"\n",
    "    assert mode in ['global','local'],'mode must be global or local'\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    tfidf_vec = TfidfTransformer(norm=norm, use_idf=use_idf, smooth_idf=smooth_idf, sublinear_tf=sublinear_tf)\n",
    "    if mode == 'global':\n",
    "        concated_countvec = getConcatedAppIDCountVector(concated_list)\n",
    "        concated_countvec.set_index('appID',inplace=True)\n",
    "        vec_columns = concated_countvec.columns\n",
    "        global_tfidf_vec = tfidf_vec.fit_transform(concated_countvec).todense()\n",
    "        global_tfidf_vec = pd.DataFrame(global_tfidf_vec,columns=vec_columns,index=concated_countvec.index).reset_index()\n",
    "        return global_tfidf_vec\n",
    "    else:\n",
    "        concated_tfidf_vec = None\n",
    "        for feature in tqdm(concated_list):\n",
    "            feature_path = feature_data_path +'CountVector_appID_user_installed_'+feature+'.pkl'\n",
    "            if os.path.exists(feature_path):\n",
    "                count_vec = load_pickle(feature_path)\n",
    "            else:\n",
    "                gen_CountVector_appID_user_installed(concated_list)\n",
    "                count_vec = load_pickle(feature_path)\n",
    "            count_vec.set_index('appID',inplace=True)\n",
    "            vec_columns = count_vec.columns\n",
    "            local_tfidf_vec = tfidf_vec.fit_transform(count_vec).todense()\n",
    "            local_tfidf_vec = pd.DataFrame(local_tfidf_vec,columns=vec_columns,index=count_vec.index).reset_index()\n",
    "            if concated_tfidf_vec is None:\n",
    "                concated_tfidf_vec = local_tfidf_vec\n",
    "            else:\n",
    "                concated_tfidf_vec = pd.merge(concated_tfidf_vec,local_tfidf_vec,'left','appID')\n",
    "        return concated_tfidf_vec\n",
    "\n",
    "\n",
    "def get_ConcatedAppIDCountVector(concated_list = ['age_cut','gender','education','marriageStatus','haveBaby',]):\n",
    "    \"\"\"\n",
    "    拼接键['appID']\n",
    "    \"\"\"\n",
    "    concated_countvec = None\n",
    "    for feature in tqdm(concated_list):\n",
    "        feature_path = feature_data_path +'CountVector_appID_user_installed_'+feature+'.pkl'\n",
    "        if os.path.exists(feature_path):\n",
    "            count_vec = load_pickle(feature_path)\n",
    "        else:\n",
    "            gen_CountVector_appID_user_installed(concated_list)\n",
    "            count_vec = load_pickle(feature_path)\n",
    "        if concated_countvec is None:\n",
    "            concated_countvec = count_vec\n",
    "        else:\n",
    "            concated_countvec = pd.merge(concated_countvec,count_vec,'left','appID')\n",
    "    return concated_countvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 计算appCategory初始被各个人群安装的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_CountVector_appCategory_user_installed(appCategory_describe_feature_names=['age_cut','gender','education','marriageStatus','haveBaby','hometown_province','residence_province']):\n",
    "    \"\"\"\n",
    "    生成根据install表计算的appID计数描述向量，可以进行其他后处理\n",
    "    拼接键['appID']\n",
    "    \"\"\"\n",
    "    user_install = load_pickle(raw_data_path+'user_installedapps.pkl')\n",
    "    user_install = addAppCategories(user_install)\n",
    "    user_info = pd.read_csv(raw_data_path+'user.csv')\n",
    "    user_info['age_cut']=pd.cut(user_info['age'],bins=[-1,0,18,25,35,45,55,65,np.inf],labels=False)\n",
    "    user_info['hometown_province'] = user_info['hometown'].apply(lambda x: x//100)\n",
    "    user_info['residence_province'] = user_info['residence'].apply(lambda x: x//100)\n",
    "    \n",
    "    for feature in tqdm(appCategory_describe_feature_names):\n",
    "        feature_path = feature_data_path +'CountVector_appCategory_user_installed_'+feature+'.pkl'\n",
    "        if os.path.exists(feature_path):\n",
    "            print('found '+feature_path)\n",
    "            continue\n",
    "        print('generating '+feature_path)\n",
    "        sub_user_info =pd.get_dummies(user_info[['userID',feature]],columns=[feature])\n",
    "        user_install = pd.merge(user_install,sub_user_info,'left','userID')\n",
    "        dummy_features= sub_user_info.columns.tolist()\n",
    "        dummy_features.remove('userID')\n",
    "        app_describe_feature = None\n",
    "        for dummy_feature in tqdm(dummy_features):\n",
    "            app_feature_installed = user_install[['appCategory',dummy_feature]].groupby('appCategory',as_index=False).sum()\n",
    "            if app_describe_feature is None:\n",
    "                app_describe_feature = app_feature_installed\n",
    "            else:\n",
    "                app_describe_feature = pd.concat([app_describe_feature,app_feature_installed[[dummy_feature]]],axis=1)\n",
    "            user_install.drop(dummy_feature,inplace=True,axis=1)\n",
    "        dump_pickle(app_describe_feature,feature_path)\n",
    "        #print('generated '+feature_path)\n",
    "\n",
    "\n",
    "def gen_CountVector_appCategory_user_action_hour():\n",
    "    \"\"\"\n",
    "    拼接键['appCategory']\n",
    "    \"\"\"\n",
    "    feature_path = feature_data_path+'CountVector_appCategory_actionHour.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_action = pd.read_csv(raw_data_path+'user_app_actions.csv')\n",
    "        app_cate = pd.read_csv(raw_data_path+'app_categories.csv')\n",
    "        user_action = pd.merge(user_action,app_cate,'left','appID')\n",
    "        user_action['installHour'] = user_action['installTime']%1000000//10000\n",
    "        user_action = pd.get_dummies(user_action[['appCategory','installHour']],columns=['installHour'])\n",
    "        user_action = user_action.groupby('appCategory',as_index=False).sum()\n",
    "        \n",
    "        dump_pickle(user_action,feature_path)\n",
    "        \n",
    "def get_TfidfVector_appCategory_user_action_hour(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False):\n",
    "    \"\"\"\n",
    "    拼接键['appCategory']\n",
    "    \"\"\"\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "    \n",
    "    feature_path = feature_data_path+'CountVector_appCategory_actionHour.pkl'\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_CountVector_appCategory_user_action_hour()\n",
    "    count_vec = load_pickle(feature_path)\n",
    "    count_vec.set_index('appCategory',inplace=True)\n",
    "    col_name = count_vec.columns\n",
    "    tfidf_vec = pd.DataFrame(tfidf.fit_transform(count_vec).todense(),columns=col_name,index=count_vec.index).reset_index()\n",
    "    return tfidf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def gen_user_hist_install():\n",
    "    train = load_pickle(raw_data_path+'train.pkl')\n",
    "    train_user_hist_install = load_pickle(feature_data_path+'train_user_hist_install')\n",
    "    train = addTime(train)\n",
    "    train_user_hist_install.index = train.index\n",
    "    train = pd.concat([train,train_user_hist_install],axis=1)\n",
    "    train_user_hist_install = train[['clickDay','userID','user_hist_install']].drop_duplicates()\n",
    "    dump_pickle(train_user_hist_install,feature_data_path+'train_user_hist_install.pkl')\n",
    "    \n",
    "    test_user_hist_install = load_pickle(feature_data_path+'test_user_hist_install')\n",
    "    dump_pickle(test_user_hist_install,feature_data_path+'test_user_hist_install.pkl')\n",
    "def add_user_hist_install(data,mode):\n",
    "    assert mode in ['train','test']\n",
    "    if mode == 'train':\n",
    "        train_user_hist_install = load_pickle(feature_data_path+'train_user_hist_install.pkl')\n",
    "        data = pd.merge(data,train_user_hist_install,'left',['clickDay','userID'])\n",
    "    elif mode=='test':\n",
    "        test_user_hist_install = load_pickle(feature_data_path+'test_user_hist_install.pkl')\n",
    "        test_user_hist_install.index = test_user_hist_install.index\n",
    "        data = pd.concat([data,test_user_hist_install],axis=1)\n",
    "    return data\n",
    "\"\"\"\n",
    "def gen_user_hist_install():\n",
    "    \"\"\"\n",
    "    记录截至clickDay前一天，用户安装的app总量，根据action表统计\n",
    "    拼接键['userID','clickDay]\n",
    "    \"\"\"\n",
    "    feature_path = feature_data_path + 'user_hist_install.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_action = pd.read_csv(raw_data_path+'user_app_actions.csv')\n",
    "        user_action['installDay'] = user_action['installTime']//1000000\n",
    "        user_hist_install = None\n",
    "        for clickday in tqdm(range(17,32)):\n",
    "            last_day_acc_install = user_action[user_action.installDay<clickday][['userID','appID']].groupby('userID',as_index=False).count()\n",
    "            last_day_acc_install['clickDay'] = clickday\n",
    "            last_day_acc_install.rename(columns={'appID':'user_hist_install'},inplace=True)\n",
    "            last_day_acc_install['user_hist_install'] = last_day_acc_install['user_hist_install']/clickday#对天数做平滑\n",
    "            if user_hist_install is None:\n",
    "                user_hist_install = last_day_acc_install\n",
    "            else:\n",
    "                user_hist_install = pd.concat([user_hist_install,last_day_acc_install],axis=0)\n",
    "        pd.to_pickle(user_hist_install,feature_path)\n",
    "def add_user_hist_install(data,mode):\n",
    "    feature_path = feature_data_path + 'user_hist_install.pkl'\n",
    "    user_hist_installed = load_pickle(feature_path)\n",
    "    data = pd.merge(data,user_hist_installed,'left',['userID','clickDay'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算各人群初始安装的appID向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_group_install():\n",
    "    user_install = load_pickle(raw_data_path+'user_installedapps.pkl')\n",
    "    user_info = load_pickle(raw_data_path+'user.pkl')\n",
    "    user_info['age_cut_small']=pd.cut(user_info['age'],bins=[-1,0,18,25,35,45,55,np.inf],labels=False)\n",
    "    user_info['education_new'] = user_info['education']\n",
    "    user_info.loc[user_info.education_new==7,'education_new'] = 6\n",
    "    user_info_comb = user_info[['age_cut_small','gender','education_new',]].drop_duplicates()\n",
    "    user_info_comb['user_group'] = np.arange(0,user_info_comb.shape[0])\n",
    "    user_info = pd.merge(user_info,user_info_comb,'left',['age_cut_small','gender','education_new',])\n",
    "    user_install = pd.merge(user_install,user_info[['userID','user_group','age_cut_small','gender','education_new',]],'left','userID')\n",
    "    def update_dict(row,dic):\n",
    "        dic[row['appID']] += 1\n",
    "    user_group_install = None\n",
    "    for i,u_g in tqdm(enumerate(user_install.user_group.unique())):\n",
    "        sub_install = user_install[user_install.user_group==u_g]\n",
    "        install_dict = dict((k,0) for k in user_install.appID.unique())\n",
    "        install_dict['user_group'] = u_g\n",
    "        install_dict['age_cut_small'] = sub_install['age_cut_small'].iloc[0]\n",
    "        install_dict['gender'] = sub_install['gender'].iloc[0]\n",
    "        install_dict['education_new'] = sub_install['education_new'].iloc[0]\n",
    "        sub_install.apply(update_dict, args=(install_dict,),axis=1,)\n",
    "        if user_group_install is None:\n",
    "            user_group_install = pd.DataFrame(install_dict,index=[i,])\n",
    "        else:\n",
    "            user_group_install = pd.concat([user_group_install,pd.DataFrame(install_dict,index=[i,])])\n",
    "    dump_pickle(user_group_install,feature_data_path+'user_group_install.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gen_user_group_install()速度太慢了，之前跑了一次崩溃了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    gen_user_start_installed_cateA()\n",
    "    gen_user_hist_install()\n",
    "    #gen_user_hist_install_cateA()\n",
    "    #gen_app_start_installed()\n",
    "    #gen_app_hist_install()\n",
    "    #gen_CountVector_appID_user_installed(['age_cut','gender','education','marriageStatus','haveBaby'])\n",
    "    #gen_CountVector_appCategory_user_installed(['age_cut','gender','education','marriageStatus','haveBaby'])\n",
    "    #gen_CountVector_appCategory_user_action_hour()\n",
    "    \n",
    "    print('all done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
