{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import load_pickle,dump_pickle,raw_data_path,feature_data_path\n",
    "from feature_joint import addTime,addAd,addPosition,addAppCategories,addUserInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_Click_stats(data,col):\n",
    "\n",
    "    clicks_user_day = pd.DataFrame(data.groupby(['userID', col])['clickTime'].count(), )\n",
    "    clicks_user_day.rename(columns={'clickTime': col+'_m'}, inplace=True)\n",
    "    clicks_user_day.reset_index(inplace=1)\n",
    "    clicks_user_day_m = pd.DataFrame(clicks_user_day.groupby(['userID'])[col+'_m'].mean()).rename(columns={col+'_m':col+'_mean'}).reset_index()\n",
    "    clicks_user_day_ma = pd.DataFrame(clicks_user_day.groupby(['userID'])[col+'_m'].max()).rename(columns={col+'_m':col+'_max'}).reset_index()\n",
    "    clicks_user_day_mi = pd.DataFrame(clicks_user_day.groupby(['userID'])[col+'_m'].min()).rename(columns={col+'_m':col+'_min'}).reset_index()\n",
    "    stats_columns = [col+'_max',col+'_mean',col+'_min']\n",
    "    data = pd.merge(data,clicks_user_day_m,how='left',on='userID')\n",
    "    data = pd.merge(data, clicks_user_day_ma, how='left', on='userID')\n",
    "    data = pd.merge(data, clicks_user_day_mi, how='left', on='userID')\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_stats_feature():\n",
    "    \"\"\"\n",
    "    输入train和test，进行concat后,添加用户点击数据的统计特征\n",
    "    注意：由于内存限制，第一次运行生成pkl文件后，返回时会报错。之后重新运行，再通过pkl文件进行拼接即可。\n",
    "    \"\"\"\n",
    "    feature_path = feature_data_path+'UserClickStats.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        train = load_pickle(raw_data_path+'train.pkl')\n",
    "        test = load_pickle(raw_data_path+'test.pkl')\n",
    "        data = train.append(test)\n",
    "        del train,test\n",
    "        gc.collect()\n",
    "        data = addTime(data)\n",
    "        data = addAd(data)\n",
    "        data = addPosition(data)\n",
    "        data = addAppCategories(data)\n",
    "        data = add_user_day_click(data,)\n",
    "        data = add_user_day_click_count(data,feature_list=['camgaignID','adID','appID','sitesetID'])\n",
    "        #data = add_user_day_hour_count(data)\n",
    "        #train_origin_features = train.columns.values.tolist()\n",
    "        #test_origin_features = test.columns.values.tolist()\n",
    "\n",
    "\n",
    "        feature_names = [ 'user_adID_click_day_mean',#有些统计特征没包括进来\n",
    "           'user_adID_click_day_min', 'user_camgaignID_click_day_min',\n",
    "           'user_appID_click_day_mean', 'user_appID_click_day_max',\n",
    "           'user_appID_click_day_min', 'user_sitesetID_click_day_mean',\n",
    "           'user_sitesetID_click_day_max', 'user_sitesetID_click_day_min',\n",
    "           'user_click_day_mean', 'user_click_day_max', 'user_click_day_min']\n",
    "                                                          \n",
    "\n",
    "        print('generating '+feature_path)\n",
    "        columns_day = ['user_adID_click_day','user_camgaignID_click_day','user_appID_click_day','user_sitesetID_click_day',\n",
    "                   'user_click_day']\n",
    "        columns_hour = ['user_adID_click_hour','user_camgaignID_click_hour','user_appID_click_hour',\n",
    "                        'user_sitesetID_click_hour']\n",
    "        sub_feature = ['userID','clickTime',]\n",
    "        #data = pd.concat([train[sub_feature+columns_day+columns_hour],test[sub_feature+columns_day+columns_hour]])\n",
    "        for col in tqdm(columns_day):\n",
    "            data = gen_Click_stats(data,col)\n",
    "        #for col in tqdm(columns_hour):\n",
    "        #    data = addClick_stats(data,col)\n",
    "            \n",
    "        data = data[feature_names+['userID']].drop_duplicates(['userID'])\n",
    "        dump_pickle(data,feature_path,)\n",
    "   \n",
    " \n",
    "    \n",
    "def add_user_click_stats(data,):\n",
    "    \n",
    "    train_click_stats = load_pickle(feature_data_path+'UserClickStats.pkl')\n",
    "    data = pd.merge(data,train_click_stats,'left','userID')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_day_click():\n",
    "    feature_path = feature_data_path+'user_day_clicks.pkl'\n",
    "    if os.path.exists(feature_path):\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        train = load_pickle(raw_data_path+'train.pkl')\n",
    "        test = load_pickle(raw_data_path+'test.pkl')\n",
    "        all_data = train.append(test)\n",
    "        all_data = addTime(all_data)\n",
    "        user_click_day = pd.DataFrame(all_data.groupby(['clickDay','userID']).size()).reset_index().rename(columns={0:'user_click_day'})\n",
    "        dump_pickle(user_click_day,feature_path)\n",
    "def add_user_day_click(data):\n",
    "    \"\"\"\n",
    "    添加用户当天的点击总数\n",
    "    拼接键['userID','clickDay',]\n",
    "    \"\"\"\n",
    "    feature_path = feature_data_path+'user_day_clicks.pkl'\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_day_click()\n",
    "    user_click_day = load_pickle(feature_path)\n",
    "    data = pd.merge(data,user_click_day,'left',['clickDay','userID'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_day_click_count(updata=False):\n",
    "    \"\"\"\n",
    "    生成所有数据的每天点击统计量\n",
    "    拼接键['ID_name','clickDay']\n",
    "    \"\"\"\n",
    "    train = load_pickle(raw_data_path+'train.pkl')\n",
    "    test = load_pickle(raw_data_path+'test.pkl')\n",
    "    data = train.append(test)\n",
    "    data = addTime(data)\n",
    "    data = addAd(data)\n",
    "    data = addAppCategories(data)\n",
    "    data = addPosition(data)\n",
    "    \n",
    "    ads_feature = ['advertiserID','camgaignID','adID','creativeID','appID','appCategory',]\n",
    "    context_feature = ['positionID','sitesetID',]\n",
    "    stats_feature = ads_feature+context_feature\n",
    "    \n",
    "    for feature in tqdm(stats_feature):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_day.pkl'\n",
    "        if os.path.exists(feature_path) and updata==False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "            user_feature_click_day = data.groupby(['userID','clickDay',feature]).size().reset_index().rename(columns={0:'user_'+feature+'_click_day'})\n",
    "            dump_pickle(user_feature_click_day,feature_path)\n",
    "            \n",
    "def gen_user_hour_click_count(update=False):\n",
    "    \"\"\"\n",
    "    生成所有数据的每天每小时点击统计量\n",
    "    拼接键['ID_name','clickDay','clickHour']\n",
    "    \"\"\"\n",
    "    train = load_pickle(raw_data_path+'train.pkl')\n",
    "    test = load_pickle(raw_data_path+'test.pkl')\n",
    "    data = train.append(test)\n",
    "    data = addTime(data)\n",
    "    data = addAd(data)\n",
    "    data = addPosition(data)\n",
    "    data = addAppCategories(data)\n",
    "    \n",
    "    ads_feature = ['advertiserID','camgaignID','adID','creativeID','appID','appCategory',]\n",
    "    context_feature = ['positionID','sitesetID',]\n",
    "    stats_feature = ads_feature+context_feature\n",
    "    \n",
    "    for feature in tqdm(stats_feature):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_hour.pkl'\n",
    "        if os.path.exists(feature_path) and update==False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "            user_feature_click_day = data.groupby(['userID','clickDay','clickHour',feature]).size().reset_index().rename(columns={0:'user_'+feature+'_click_hour'})\n",
    "            dump_pickle(user_feature_click_day,feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_user_day_click_count(data,feature_list=['positionID','advertiserID','camgaignID','adID','creativeID','appID','sitesetID',]):\n",
    "    \"\"\"\n",
    "    data必须包含clickDay字段，可以通过addTime，addAD,addPostion,addAppCategories添加\n",
    "    \"\"\"\n",
    "    ads_feature = ['advertiserID','camgaignID','adID','creativeID','appID',]\n",
    "    context_feature = ['positionID','sitesetID',]\n",
    "    stats_feature = ads_feature+context_feature\n",
    "    #assert any([feature_list==stats_feature[i:i+len(feature_list)] for i in range(0,len(stats_feature)-len(feature_list)+1)]),'feature_list must be in stats_feature'\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_day.pkl'\n",
    "        feature_day_click = load_pickle(feature_path)\n",
    "        data = pd.merge(data,feature_day_click,'left',[feature,'clickDay','userID'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_user_day_hour_count(data,feature_list=['positionID','advertiserID','camgaignID','adID','creativeID','appID',]):\n",
    "    \"\"\"\n",
    "    data必须包含clickHour等字段，可以通过addTime，addAD,addPostion,addAppCategories添加\n",
    "    \"\"\"\n",
    "    ads_feature = ['advertiserID','camgaignID','adID','creativeID','appID',]\n",
    "    context_feature = ['positionID','sitesetID',]\n",
    "    stats_feature = ads_feature+context_feature\n",
    "    #assert any([feature_list==stats_feature[i:i+len(feature_list)] for i in range(0,len(stats_feature)-len(feature_list)+1)]),'feature_list must be in stats_feature'\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_hour.pkl'\n",
    "        feature_day_click = load_pickle(feature_path)\n",
    "        data = pd.merge(data,feature_day_click,'left',[feature,'clickDay','clickHour','userID'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../feature_data/user_day_clicks.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 2326.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../feature_data/user_advertiserID_click_day.pkl\n",
      "found ../feature_data/user_camgaignID_click_day.pkl\n",
      "found ../feature_data/user_adID_click_day.pkl\n",
      "found ../feature_data/user_creativeID_click_day.pkl\n",
      "found ../feature_data/user_appID_click_day.pkl\n",
      "found ../feature_data/user_appCategory_click_day.pkl\n",
      "found ../feature_data/user_positionID_click_day.pkl\n",
      "found ../feature_data/user_sitesetID_click_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 921.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../feature_data/user_advertiserID_click_hour.pkl\n",
      "found ../feature_data/user_camgaignID_click_hour.pkl\n",
      "found ../feature_data/user_adID_click_hour.pkl\n",
      "found ../feature_data/user_creativeID_click_hour.pkl\n",
      "found ../feature_data/user_appID_click_hour.pkl\n",
      "found ../feature_data/user_appCategory_click_hour.pkl\n",
      "found ../feature_data/user_positionID_click_hour.pkl\n",
      "found ../feature_data/user_sitesetID_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:42<00:00, 51.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../feature_data/UserClickStats.pkl\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    gen_user_day_click()\n",
    "    gen_user_day_click_count()\n",
    "    gen_user_hour_click_count()\n",
    "    generate_stats_feature()\n",
    "    print('all done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
