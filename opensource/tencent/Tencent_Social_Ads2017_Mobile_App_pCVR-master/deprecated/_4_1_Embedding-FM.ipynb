{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.sparse import coo_matrix\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../ffm_cache/online_train_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = train.iloc[10602212:13625807,:]\n",
    "train = train.iloc[0:10602212,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = ['age_cut','gender', 'education', 'marriageStatus', 'haveBaby','appID','creativeID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_features = ['creativeID', 'userID', 'positionID', 'connectionType',\n",
    "       'telecomsOperator', 'age', 'gender', 'education', 'marriageStatus',\n",
    "       'haveBaby', 'ht_province', 'rd_province', 'sitesetID', 'positionType',\n",
    "       'adID', 'camgaignID', 'advertiserID', 'appID', 'appPlatform',\n",
    "       'appCategory', 'trick', 'clickHour', 'first_diff', 'last_diff',\n",
    "       'install2click', 'posSum_online', 'creSum_online', 'userSum_online',\n",
    "       'adSum_online', 'appSum_online', 'positionID_cvr_smooth',\n",
    "       'creativeID_cvr', 'userID_cvr', 'adID_cvr', 'appID_cvr',\n",
    "       'user_hist_install', 'installed_cate_0', 'installed_cate_1',\n",
    "       'installed_cate_2', 'installed_cate_3', 'installed_cate_4',\n",
    "       'installed_cate_5', 'user_ad_click_day', 'user_camgaign_click_day',\n",
    "       'user_camgaign_click_hour', 'user_app_click_day', 'user_app_click_hour',\n",
    "       'user_site_click_day', 'user_site_click_hour', 'user_click_day',\n",
    "       'user_ad_click_day_min', 'user_camgaign_click_day_min',\n",
    "       'user_app_click_day_max', 'user_app_click_day_min',\n",
    "       'user_site_click_day_max', 'user_site_click_day_min',\n",
    "       'user_click_day_max', 'user_click_day_min', 'user_ad_click_day_mean',\n",
    "       'user_app_click_day_mean', 'user_site_click_day_mean',\n",
    "       'user_click_day_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:31<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "lbe = LabelEncoder()\n",
    "id_size_dict ={}\n",
    "for feature in tqdm(cate_features):\n",
    "    train[feature] = lbe.fit_transform(train[feature])\n",
    "    id_size_dict[feature] = train[feature].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x = train.iloc[2901508:5925103,:]\n",
    "train_x = train.iloc[0:2901508,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_size_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in cate_features:\n",
    "    id_size_list.append(id_size_dict[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(fetches,sess, X=None, y=None, ):\n",
    "        feed_dict = {}\n",
    "        if type(X) is list:\n",
    "            for i in range(len(X)):\n",
    "                feed_dict[id_inputs[i]] = X[i]\n",
    "                #print(feed_dict[id_inputs[i]])\n",
    "        else:\n",
    "            feed_dict[id_inputs] = X\n",
    "        if y is not None:\n",
    "            feed_dict[label_inputs] = y\n",
    "        return sess.run(fetches, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_feature = cate_features#['appID','gender','connectionType']\n",
    "embedding_size =8\n",
    "id_dtype= tf.int32\n",
    "id_field_num = len(input_feature)\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(0)\n",
    "    global_step =  tf.Variable(0,dtype=tf.int32,trainable=False,name='global_step')\n",
    "\n",
    "    with tf.name_scope('ID_input'):\n",
    "        id_inputs =[tf.placeholder(id_dtype,shape=[None,]) for i in range(id_field_num)]\n",
    "        label_inputs = tf.placeholder(tf.float32)\n",
    "    \n",
    "    with tf.name_scope('Embedding_matrix'):\n",
    "        embeddings = [tf.Variable(tf.ones([id_size_list[i],embedding_size],)) for i in range(0,id_field_num)]\n",
    "        #embedding1 = tf.Variable(tf.ones([id_size,embedding_size],))\n",
    "        #embedding2 = tf.Variable(tf.ones([id_size,embedding_size],))\n",
    "        #embedding3 = tf.Variable(tf.ones([id_size,embedding_size],))\n",
    "        onehot_embeddings = [tf.Variable(tf.random_normal([id_size_list[i],1])) for i in range(0,id_field_num)]\n",
    "        #onehot_embedding1 = tf.Variable(tf.random_normal([id_size,1]))\n",
    "        #onehot_embedding2 = tf.Variable(tf.random_normal([id_size,1]))\n",
    "        #onehot_embedding3 = tf.Variable(tf.random_normal([id_size,1]))\n",
    "    \n",
    "    with tf.name_scope('Embedding_layer'):\n",
    "        embeds = [tf.nn.embedding_lookup(embeddings[i],id_inputs[i]) for i in range(0,id_field_num)]\n",
    "        #embed1 = tf.nn.embedding_lookup(embedding1,appID)\n",
    "        #embed2 = tf.nn.embedding_lookup(embedding2,genderID)\n",
    "        #embed3 = tf.nn.embedding_lookup(embedding3,connectionTypeID)\n",
    "        \n",
    "        onehot_embeds = [tf.nn.embedding_lookup(onehot_embeddings[i],id_inputs[i]) for i in range(0,id_field_num)]\n",
    "        #onehot_embed1 = tf.nn.embedding_lookup(onehot_embedding1,appID)\n",
    "        #onehot_embed2 = tf.nn.embedding_lookup(onehot_embedding2,genderID)\n",
    "        #onehot_embed3 = tf.nn.embedding_lookup(onehot_embedding3,connectionTypeID)\n",
    "    \n",
    "    with tf.name_scope('FM_layer'):\n",
    "        fm_units = []\n",
    "        embed_list=embeds#[embed1,embed2,embed3]\n",
    "        for i in range(0,id_field_num):\n",
    "            for j in range(i+1,id_field_num):\n",
    "                temp = tf.reduce_sum(tf.multiply(embed_list[i],embed_list[j]),axis=1)\n",
    "                fm_units.append(temp)\n",
    "\n",
    "        sum_fm_units =tf.reduce_sum(fm_units,0)\n",
    "        single_onehot_list = tf.concat(onehot_embeds,1)\n",
    "        sum_linear_units = tf.reduce_sum(single_onehot_list,1)\n",
    "    with tf.name_scope('Output'):\n",
    "        logits = tf.add(sum_fm_units,sum_linear_units)\n",
    "        prob = tf.sigmoid(logits)\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=label_inputs,logits=logits))\n",
    "        batch_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=label_inputs,logits=logits))\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss,global_step=global_step)\n",
    "        #optimizer = tf.train.FtrlOptimizer(0.05).minimize(loss,global_step=global_step)\n",
    "    with tf.name_scope('Summary'):\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_feature = cate_features\n",
    "early_stop_round = 20\n",
    "min_loss = 1e9\n",
    "chance_round = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = train_x.shape[0]\n",
    "valid_size = test_x.shape[0]\n",
    "batch_size = 1024#10240\n",
    "valid_batch_size = 10240\n",
    "batch_num = train_size//batch_size\n",
    "valid_batch_num = valid_size//valid_batch_size\n",
    "num_round = 1000\n",
    "va_input_X = [test_x[feature].values for feature in input_feature]\n",
    "va_input_y = test_x['label'].values\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    writer = tf.summary.FileWriter('./deepFM_log/',graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_round):\n",
    "        \n",
    "        for j in tqdm(range(0,1+batch_num)): \n",
    "            X_i = train_x.iloc[j*batch_size:min((j+1)*batch_size,train_size)]\n",
    "            input_X = [X_i[feature].values for feature in input_feature]#X_i[input_feature]\n",
    "            input_y =X_i['label'].values\n",
    "            _,l,summary = run([optimizer,loss,summary_op],sess=sess,X = input_X,y = input_y)\n",
    "\n",
    "        va_loss_sum = 0 \n",
    "        for j in range(0,1+valid_batch_num):\n",
    "            X_i = test_x.iloc[j*valid_batch_size:min((j+1)*valid_batch_size,valid_size)]\n",
    "            input_X = [X_i[feature].values for feature in input_feature]#X_i[input_feature]\n",
    "            input_y =X_i['label'].values\n",
    "            va_batch_loss = run([batch_loss,],sess=sess,X=input_X,y=input_y,)\n",
    "            va_loss_sum += va_batch_loss[0]\n",
    "        \n",
    "        va_loss = va_loss_sum/valid_size\n",
    "        print('epoch {0} va-loss {1:.7f}'.format(i,va_loss))\n",
    "        if va_loss < min_loss:\n",
    "            min_loss = va_loss\n",
    "            chance_round = 0\n",
    "        else:\n",
    "            chance_round +=1\n",
    "        if va_loss < 0.104 or chance_round > early_stop_round:\n",
    "            print('done')\n",
    "            saver.save(sess,'./LR_log/save_model',global_step=global_step)\n",
    "            break\n",
    "    \n",
    "        saver.save(sess,'./FM_log/save_model',global_step=global_step)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9091137032515957"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
